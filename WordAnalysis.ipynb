{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import pronouncing\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "from HMM_helper import (\n",
    "    text_to_wordcloud,\n",
    "    states_to_wordclouds,\n",
    "    parse_observations,\n",
    "    sample_sentence,\n",
    "    visualize_sparsities,\n",
    "    animate_emission\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function from set 6 to parse the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in the data and preprocess it. We want to create a dictionary for rhymes and a dictionary for which stress the word starts with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), \\\n",
    "                         'Release/data/shakespeare.txt')).read()\n",
    "obs, obs_map = parse_observations(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the HMM class from the homework 6 solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can first get the syllable counts of our text by reading in from our syllable dictionary and saving the counts for number of syllables.\n",
    "\n",
    "Our syllable dictionary is in the form of {integer index: \\[array of possible syllable values]}, where the array stores a second value if there is another number of syllables we can have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 'E2']\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "# here we can get the syllables\n",
    "\n",
    "file = open('Release/data/Syllable_dictionary.txt', 'r')\n",
    "\n",
    "syllable_dict = {}\n",
    "keys = obs_map.keys()\n",
    "# print(len(obs_map.keys()))\n",
    "# i = 0\n",
    "for line in file:\n",
    "    l = line.strip().split()\n",
    "    \n",
    "    # all our words are saved to the observation dictionary with\n",
    "    # special characters taken out, so we must use this regular\n",
    "    # expression to strip out the special characters\n",
    "    word = re.sub(r'[^\\w]', '', l[0]).lower()\n",
    "    if word in keys:\n",
    "        l = sorted(l[1:])\n",
    "        for i in range(len(l)):\n",
    "            try:\n",
    "                l[i] = int(l[i])\n",
    "            except ValueError:\n",
    "                continue\n",
    "        syllable_dict[obs_map[word]] = l\n",
    "        # print(word, l)\n",
    "        # i += 1\n",
    "\n",
    "print(syllable_dict[obs_map['adoting']])\n",
    "print(syllable_dict[obs_map['even']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the nltk corpus cmudict dataset to get the pronounciations for the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586\n"
     ]
    }
   ],
   "source": [
    "# get the words that aren't known - just for reference\n",
    "unknown = []\n",
    "\n",
    "for key, value in obs_map.items():\n",
    "    #print(key, value)\n",
    "    if(key not in reference.keys()):\n",
    "        unknown.append(key)\n",
    "\n",
    "print(len(unknown))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['W', 'EH1', 'N'], ['HH', 'W', 'EH1', 'N'], ['W', 'IH1', 'N'], ['HH', 'W', 'IH1', 'N']]\n",
      "[['B', 'UH1', 'L', 'SH', 'IH2', 'T']]\n",
      "[['P', 'IY0', 'AE1', 'N', 'AH0', 'S', 'T'], ['P', 'IY0', 'AA1', 'N', 'AH0', 'S', 'T'], ['P', 'IY1', 'AH0', 'N', 'IH0', 'S', 'T']]\n"
     ]
    }
   ],
   "source": [
    "# see if our referencing works\n",
    "\n",
    "print(reference['when'])\n",
    "print(reference['bullshit'])\n",
    "print(reference['pianist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below goes through all our words, and gets the final stress of the word, by examining the stress pattern and extracting the value of the last stress. In the case where there are multiple stress patterns for the word, and the last stresses are different, the code randomly chooses a pattern. If there are 3 patterns for a word, 2 which end in a stressed syllable, and 1 which ends unstressed, it is more likely to choose the stressed syllable.\n",
    "\n",
    "\n",
    "Our stress dictionary is in the form {index, stress value} where stress value is 1 for stressed and 0 for unstressed, and is chosen randomly from the possible final stresses we can have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go though all our words\n",
    "\n",
    "# if it's in references, get the last syllable with\n",
    "# an integer value at the end\n",
    "\n",
    "# if the integer > 0, then it is stressed, if not it\n",
    "# is unstressed\n",
    "\n",
    "stress = {}\n",
    "lastVow = {}\n",
    "count = 0\n",
    "# first lets go through all our words\n",
    "for key, value in obs_map.items():\n",
    "    # now go through all the ones in our references\n",
    "    if(key in reference.keys()):\n",
    "        # if(len(reference[key]) > 1):\n",
    "        # go through the possible pronounciations, from\n",
    "        # the end, and get the last vowel\n",
    "\n",
    "        diff = []\n",
    "        for pronounce in reference[key]:\n",
    "            # this is only a \"vowel\" if the last character\n",
    "            # is an integer\n",
    "            # now iterate backwards through the strings in\n",
    "            # the pronounciation, and get the k\n",
    "            for i in range(len(pronounce) - 1, -1, -1):\n",
    "                try:\n",
    "                    # this will add the entire pronounciation\n",
    "                    # and integer to our array\n",
    "                    int(pronounce[i][-1])\n",
    "\n",
    "                    # get rid of the -1 index if we want to look\n",
    "                    # at the actual pronounciation\n",
    "                    \n",
    "                    # if we need to, we can count syllables here as well\n",
    "                    # just by adding a count, and commenting out the break\n",
    "                    # count += 1\n",
    "                    \n",
    "                    # there are acutally 2 types of stressed pronounciation\n",
    "                    # here we don't care which one it is\n",
    "                    diff.append(int(pronounce[i][-1]) % 2)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        lastVow[value] = diff\n",
    "        # syllables will just have the random choice of our lastVow for now\n",
    "        stress[value] = random.choice(diff)\n",
    "\n",
    "    # if we don't know, we'll just set it to random for now\n",
    "    else:\n",
    "        count += 1\n",
    "        lastVow[value] = [0, 1]\n",
    "        stress[value] = random.choice([0, 1])\n",
    "# print(count)\n",
    "# print(len(obs_map))\n",
    "# print(lastVow[1], stress[1])\n",
    "# print(stress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680 values with different stress on the last value\n"
     ]
    }
   ],
   "source": [
    "# see how many have different stresses on the last value\n",
    "count = 0\n",
    "for key, value in lastVow.items():\n",
    "    last = value[0]\n",
    "    for e in value:\n",
    "        if e != last:\n",
    "            count += 1\n",
    "            # print(key, reference[key])\n",
    "            break\n",
    "            \n",
    "print(str(count), 'values with different stress on the last value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following code gets the syllables of the words, and adds it to syllable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3330\n",
      "['3', 'E2']\n"
     ]
    }
   ],
   "source": [
    "# here we can get the syllables\n",
    "\n",
    "file = open('Release/data/Syllable_dictionary.txt', 'r')\n",
    "\n",
    "syllable_dict = {}\n",
    "keys = obs_map.keys()\n",
    "print(len(obs_map.keys()))\n",
    "i = 0\n",
    "for line in file:\n",
    "    l = line.strip().split()\n",
    "    \n",
    "    # all our words are saved to the observation dictionary with\n",
    "    # special characters taken out, so we must use this regular\n",
    "    # expression to strip out the special characters\n",
    "    word = re.sub(r'[^\\w]', '', l[0]).lower()\n",
    "    if word in keys:\n",
    "        syllable_dict[obs_map[word]] = sorted(l[1:])\n",
    "        i += 1\n",
    "\n",
    "print(syllable_dict[obs_map['adoting']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(stress[obs_map['from']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 85 known ones have different stress on the last value\n",
    "# 586 more have unknown stress on the last value\n",
    "# these numbers include our numbers at the top of each poem (for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. So after writing the above code to generate the stress patterns, I found a the pronouncing library, which uses the cmu data and can apparently do the same thing. We won't be using this library for stress patterns, but we will be for finding rhymes. The import has been added to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accredit', 'armpit', 'baby-sit', 'beckwitt', 'cockpit', 'counterfeit', 'counterfeit', 'dipshit', 'drillbit', 'goldschmidt', 'hammerschmidt', 'horgavitt', 'horseshit', 'hypocrite', 'identikit', 'kleinschmidt', 'kuhlenschmidt', 'mandalit', 'messerschmidt', 'messerschmitt', 'misfit', 'moonlit', 'outfit', 'outwit', 'permit', 'pettit', 'pettitt', 'pettitte', 'proudfit', 'retrofit', 'rootkit', 'sunlit', 'tanartkit', 'telit', 'tidbit', 'waffenschmidt', 'waldschmidt', 'wolfenschmidt']\n"
     ]
    }
   ],
   "source": [
    "# as a test:\n",
    "print(pronouncing.rhymes('bullshit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets limit our rhyming to our data set\n",
    "def getRhyme(word):\n",
    "    if word in reference.keys():\n",
    "        rhymes = pronouncing.rhymes(word)\n",
    "        # we can just take a set different here\n",
    "        return sorted(list(set(rhymes) - (set(rhymes) - set(obs_map.keys()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['counterfeit', 'permit']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's test this\n",
    "getRhyme('bullshit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
