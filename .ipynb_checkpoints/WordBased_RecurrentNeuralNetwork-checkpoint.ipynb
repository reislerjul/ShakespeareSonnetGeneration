{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function from set 6 to parse the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "        \n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), \\\n",
    "                         'Release/data/shakespeare.txt')).read()\n",
    "obs, obs_map = parse_observations(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has %d chars, %d unique (98029, 71)\n"
     ]
    }
   ],
   "source": [
    "all_chars = list(text)\n",
    "words = text.split()\n",
    "chars = sorted(list(set(text)))\n",
    "data_size, vocab_size = len(text), len(chars)\n",
    "print ('data has %d chars, %d unique' ,(data_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_to_index = {char:idx for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_char = {idx:char for idx, char in enumerate(chars)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '6', 16: '7', 17: '8', 18: '9', 19: ':', 20: ';', 21: '?', 22: 'A', 23: 'B', 24: 'C', 25: 'D', 26: 'E', 27: 'F', 28: 'G', 29: 'H', 30: 'I', 31: 'J', 32: 'K', 33: 'L', 34: 'M', 35: 'N', 36: 'O', 37: 'P', 38: 'R', 39: 'S', 40: 'T', 41: 'U', 42: 'V', 43: 'W', 44: 'Y', 45: 'a', 46: 'b', 47: 'c', 48: 'd', 49: 'e', 50: 'f', 51: 'g', 52: 'h', 53: 'i', 54: 'j', 55: 'k', 56: 'l', 57: 'm', 58: 'n', 59: 'o', 60: 'p', 61: 'q', 62: 'r', 63: 's', 64: 't', 65: 'u', 66: 'v', 67: 'w', 68: 'x', 69: 'y', 70: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_step = 2\n",
    "s_len = 40\n",
    "training_data = []\n",
    "next_char = []\n",
    "for i in range(0, len(text)-s_len, n_step):\n",
    "    string_to_add = text[i:i + s_len]\n",
    "    training_data.append(string_to_add)\n",
    "    if i + s_len < len(text)-1:\n",
    "        next_char.append(text[i + s_len])\n",
    "    \n",
    "# This is our end symbol $\n",
    "next_char.append(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48995\n",
      "48995\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(len(next_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.zeros((len(training_data), s_len, len(chars)))\n",
    "trainY = np.zeros((len(training_data), len(chars)))\n",
    "\n",
    "for sent_idx in range(0, len(training_data)):\n",
    "    curr_sentence = training_data[sent_idx]\n",
    "    curr_next_char = next_char[sent_idx]\n",
    "    for i, char in enumerate(curr_sentence):\n",
    "        trainX[sent_idx, i, char_to_index[char]] = 1\n",
    "    trainY[sent_idx, char_to_index[curr_next_char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_train_data = []\n",
    "for data in training_data:\n",
    "    list_train_data.append(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  e t\n",
      "[' ', '1', '\\n', 'F', 'r', 'o', 'm', 'f', 'a', 'i', 'e', 's', 't', 'c', 'u', 'w', 'd', 'n', ',', 'T', 'h', 'b', 'y', \"'\", 'g', 'v', 'B', 'p', 'l', 'H', ':', '-', 'M', 'k', 'A', 'W', 'P', '.', '2', 'z', ';', 'I', 'S', 'x', '3', 'L', 'N', 'D', '?', 'O', 'C', '4', 'U', 'q', '5', '6', '7', 'j', 'R', 'Y', '(', ')', '8', '9', '0', 'G', 'V', 'E', 'K', '!', 'J']\n",
      "V J K\n"
     ]
    }
   ],
   "source": [
    "w2v_model = word2vec.Word2Vec(list_train_data)\n",
    "#w2v_model = word2vec.Word2Vec(list_train_data, iter=10, min_count=10, size=300, workers=4)\n",
    "print(w2v_model.wv.index2word[0], w2v_model.wv.index2word[1], w2v_model.wv.index2word[2])\n",
    "vocab_size = len(w2v_model.wv.vocab)\n",
    "vec_words = list(w2v_model.wv.vocab)\n",
    "print(vec_words)\n",
    "print(w2v_model.wv.index2word[vocab_size - 1], w2v_model.wv.index2word[vocab_size - 2], w2v_model.wv.index2word[vocab_size - 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-74e5b6a78b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(RNN(128, input_shape=(s_len, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#train the model\n",
    "\n",
    "#print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop')\n",
    "model.fit(trainX, trainY, batch_size = 128, nb_epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall i compare thee to a summer's day?\n",
      "Than should his bearth of love and thing disheded.\n",
      "That heart of lect born with thy shall stear,\n",
      "And to be cores me an me, and buty,\n",
      "And such than should have fair of the love,\n",
      "That this for to eare that with thy reserv,\n",
      "And to nour livess wham I to be others,\n",
      "And my to be buther bust which I doobs,\n",
      "  And surmer best for my self sime, in sean,\n",
      "And it himpith and did comprits of all\n",
      "otherst,\n",
      "And thin me branget me faill be than she dothee,\n",
      "  Thou art his black and say the sum for I shade,\n",
      "The eremy with belund is in the fire,\n",
      "The base the reston shall batien to give his drade.\n",
      "The hath in my sourngions on thy gract,\n",
      "And to have to me besing and is thy sied,\n",
      "The sean and thie still that thou shave, the owe,\n",
      "  Thes rumbers no mann, will thou mint ewe,\n",
      "  if to the surmpresse than she will grace,\n",
      "Withingt thou thy sweet fare's now thou art,\n",
      "Where in the shall wat my most mind eyes hear,\n",
      "Whon thy shall be that foul such mise shell,\n",
      "Whounst my self all thans and thise sooll\n",
      "t and seem,\n",
      "And th\n"
     ]
    }
   ],
   "source": [
    "start_index = np.random.randint(0, len(text)-s_len-1)\n",
    "start_index = 50\n",
    "sentence = text[start_index: start_index + s_len]\n",
    "sentence = \"shall i compare thee to a summer's day?\\n\"\n",
    "sequence = sentence\n",
    "for i in range(1000):\n",
    "    x_pred = np.zeros((1, s_len, len(chars)))\n",
    "    for j, char in enumerate(sentence):\n",
    "        x_pred[0, j, char_to_index[char]] = 1.\n",
    "        \n",
    "    predictions = np.array(model.predict(x_pred)[0])\n",
    "    max_index = np.argmax(predictions)\n",
    "    next_char = index_to_char[max_index]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    sequence += next_char\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "index = np.random.choice(len(chars), 1, predictions.all())\n",
    "print(index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ire increase,\n",
      "That thereby beauty's rose see flow Ind sweart\n",
      "That of you sway woth from wey shy bideds,\n",
      "And mire hele reain be rained in you.\n",
      "\n",
      "\n",
      "                    12ed I camputain inding me ,\n",
      "Teme in the weery wertting selfour sight\n",
      "robt comber yot curnton to toke you sheart,\n",
      "Whorlf at atbeasts and for mind ewe dig:ue,\n",
      "atissred out doth ver,\n",
      "at enit monks the rooner to the owers make,\n",
      "Whoreming thee 'it stmer, frulless in thy hings,\n",
      "And be2ty creets shame arver in the is detheed.\n",
      "Thou a not thich my worch you bid, bul dead.\n",
      "Then the eanth thou dongubhicg ofor mode,\n",
      "And hate sungers of thy night,\n",
      "How me, no or the vine hempastis wakl mus,\n",
      "With uple miny of bain ampelsiof how rasth.\n",
      "That pursh the thou my lies, why fordity nombull,\n",
      "And loat of lais and not for shind soo\n",
      ",\n",
      "So waln I ar form ar monking heave.\n",
      "When I an umenor bely faily done, Inong.\n",
      "vend ny llone, without mondon merlinges ampare ince sweirnge,\n",
      "When I ar mventer, and then me nom thou art.\n",
      "  Ther that in my singll to mise me,\n",
      "A dough withiven though druphy oftren\n"
     ]
    }
   ],
   "source": [
    "start_index = np.random.randint(0, len(text)-s_len-1)\n",
    "start_index = 50\n",
    "sentence = text[start_index: start_index + s_len]\n",
    "sequence = sentence\n",
    "for i in range(1000):\n",
    "    x_pred = np.zeros((1, s_len, len(chars)))\n",
    "    for j, char in enumerate(sentence):\n",
    "        x_pred[0, j, char_to_index[char]] = 1.\n",
    "        \n",
    "    predictions = np.array(model.predict(x_pred)[0])\n",
    "    #max_index = np.argmax(predictions)\n",
    "    index = np.random.choice(len(chars), 1, p=predictions)[0]\n",
    "    next_char = index_to_char[index]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    sequence += next_char\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "71\n",
      "0.730325\n",
      "1\n",
      "[  6.94062852e-04   7.30325460e-01   1.18445519e-06   7.78295682e-04\n",
      "   1.11060372e-05   7.64163997e-06   2.44515250e-03   5.60624612e-05\n",
      "   2.19699068e-04   5.26500116e-06   2.41895978e-05   3.95123561e-06\n",
      "   5.21234870e-06   6.64439176e-06   5.94937501e-06   1.87032833e-06\n",
      "   3.34175570e-06   3.50042365e-06   3.44382511e-06   8.43042362e-05\n",
      "   1.56733108e-06   3.46993038e-05   2.34842213e-04   9.26001521e-05\n",
      "   1.01433932e-06   5.02007242e-06   4.80299718e-07   6.68773864e-05\n",
      "   6.11881489e-07   2.46848376e-05   1.70587271e-03   2.24313212e-09\n",
      "   1.10972440e-08   1.80436655e-05   3.18466082e-05   2.87337753e-05\n",
      "   6.46860281e-05   4.98809823e-06   9.20415971e-07   8.35577594e-05\n",
      "   7.51566084e-04   7.88684019e-07   1.68324221e-09   1.43170066e-04\n",
      "   4.98383315e-06   1.99320279e-02   3.33607686e-03   2.89679645e-03\n",
      "   1.38006210e-02   2.89650504e-02   6.97758840e-03   1.96235511e-03\n",
      "   1.81529578e-02   1.79779790e-02   2.02268620e-05   7.90904975e-04\n",
      "   1.11462157e-02   7.73747545e-03   2.35713702e-02   2.51614377e-02\n",
      "   2.19918229e-03   1.84778310e-05   1.21617801e-02   1.51645746e-02\n",
      "   3.21238004e-02   4.12663165e-03   9.03391687e-04   8.15809052e-03\n",
      "   1.30535655e-05   4.71350085e-03   5.96043492e-07]\n"
     ]
    }
   ],
   "source": [
    "print(len(x_pred))\n",
    "print(len(predictions))\n",
    "print(max(predictions))\n",
    "print(np.argmax(predictions))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
